{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".8\"\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from lal import GreenwichMeanSiderealTime\n",
    "from gwpy.timeseries import TimeSeries\n",
    "import bilby\n",
    "from gwosc.datasets import event_detectors\n",
    "\n",
    "from ripple.waveforms.IMRPhenomD import gen_IMRPhenomD_polar\n",
    "from jimgw.PE.detector_preset import * \n",
    "# from jimgw.PE.heterodyneLikelihood import make_heterodyne_likelihood\n",
    "from jimgw.PE.detector_projection import make_detector_response\n",
    "\n",
    "from flowMC.nfmodel.rqSpline import RQSpline\n",
    "from flowMC.sampler.Sampler import Sampler\n",
    "from flowMC.sampler.MALA import MALA\n",
    "from flowMC.utils.PRNG_keys import initialize_rng_keys\n",
    "from flowMC.nfmodel.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'GW150914'\n",
    "\n",
    "minimum_frequency = 20\n",
    "maximum_frequency = 1024\n",
    "\n",
    "trigger_time = 1126259462.4\n",
    "duration = 4 \n",
    "post_trigger_duration = 2\n",
    "epoch = duration - post_trigger_duration\n",
    "gmst = GreenwichMeanSiderealTime(trigger_time)\n",
    "f_ref = 20\n",
    "f_sample = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:17 bilby INFO    : Generating frequency domain strain from given time domain strain.\n",
      "00:17 bilby INFO    : Applying a tukey window with alpha=0.1, roll off=0.2\n",
      "00:17 bilby INFO    : Generating frequency domain strain from given time domain strain.\n",
      "00:17 bilby INFO    : Applying a tukey window with alpha=0.1, roll off=0.2\n"
     ]
    }
   ],
   "source": [
    "detectors=event_detectors(event)\n",
    "ifos = bilby.gw.detector.InterferometerList(detectors)\n",
    "\n",
    "for detector in ifos:\n",
    "    analysis_data = TimeSeries.fetch_open_data(detector.name, trigger_time-duration+post_trigger_duration, trigger_time+post_trigger_duration, sample_rate=f_sample, cache=True)\n",
    "    detector.set_strain_data_from_gwpy_timeseries(analysis_data)\n",
    "\n",
    "H1_frequency = ifos[1].frequency_array\n",
    "H1_data = ifos[1].frequency_domain_strain\n",
    "H1_psd_frequency, H1_psd_temp = np.genfromtxt('/Users/ckng419/Library/CloudStorage/OneDrive-TheChineseUniversityofHongKong/Year 3 Summer Intern/Gravitional Wave/PE Setting/psd/GW150914_psd_H1.dat').T\n",
    "if H1_psd_frequency[1] - H1_psd_frequency[0] == H1_frequency[1] - H1_frequency[0]:\n",
    "    H1_psd = np.full(len(H1_frequency), np.inf)\n",
    "    for i in range(len(H1_psd_frequency)):\n",
    "        H1_psd[i] = H1_psd_temp[i]\n",
    "else:\n",
    "    print('df of H1 PSD is not equal to df of H1 data')\n",
    "\n",
    "H1_data = H1_data[(H1_frequency>minimum_frequency)*(H1_frequency<maximum_frequency)]\n",
    "H1_psd = H1_psd[(H1_frequency>minimum_frequency)*(H1_frequency<maximum_frequency)]\n",
    "H1_frequency = H1_frequency[(H1_frequency>minimum_frequency)*(H1_frequency<maximum_frequency)]\n",
    "\n",
    "L1_frequency = ifos[0].frequency_array\n",
    "L1_data = ifos[0].frequency_domain_strain\n",
    "L1_psd_frequency, L1_psd_temp = np.genfromtxt('/Users/ckng419/Library/CloudStorage/OneDrive-TheChineseUniversityofHongKong/Year 3 Summer Intern/Gravitional Wave/PE Setting/psd/GW150914_psd_L1.dat').T\n",
    "if L1_psd_frequency[1] - L1_psd_frequency[0] == L1_frequency[1] - L1_frequency[0]:\n",
    "    L1_psd = np.full(len(L1_frequency), np.inf)\n",
    "    for i in range(len(L1_psd_frequency)):\n",
    "        L1_psd[i] = L1_psd_temp[i]\n",
    "else:\n",
    "    print('df of L1 PSD is not equal to df of L1 data')\n",
    "\n",
    "L1_data = L1_data[(L1_frequency>minimum_frequency)*(L1_frequency<maximum_frequency)]\n",
    "L1_psd = L1_psd[(L1_frequency>minimum_frequency)*(L1_frequency<maximum_frequency)]\n",
    "L1_frequency = L1_frequency[(L1_frequency>minimum_frequency)*(L1_frequency<maximum_frequency)]\n",
    "\n",
    "H1 = get_H1()\n",
    "H1_response = make_detector_response(H1[0], H1[1])\n",
    "L1 = get_L1()\n",
    "L1_response = make_detector_response(L1[0], L1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_waveform_H1(f, theta, epoch, gmst, f_ref):\n",
    "#     theta_waveform = theta[:8]\n",
    "#     theta_waveform = theta_waveform.at[5].set(0)\n",
    "#     ra = theta[9]\n",
    "#     dec = theta[10]\n",
    "#     hp, hc = gen_IMRPhenomD_polar(f, theta_waveform, f_ref)\n",
    "#     return H1_response(f, hp, hc, ra, dec, gmst , theta[8]) * jnp.exp(-1j*2*jnp.pi*f*(epoch+theta[5]))\n",
    "\n",
    "# def gen_waveform_L1(f, theta, epoch, gmst, f_ref):\n",
    "#     theta_waveform = theta[:8]\n",
    "#     theta_waveform = theta_waveform.at[5].set(0)\n",
    "#     ra = theta[9]\n",
    "#     dec = theta[10]\n",
    "#     hp, hc = gen_IMRPhenomD_polar(f, theta_waveform, f_ref)\n",
    "#     return L1_response(f, hp, hc, ra, dec, gmst, theta[8]) * jnp.exp(-1j*2*jnp.pi*f*(epoch+theta[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def negative_LogLikelihood(theta):\n",
    "    \"\"\"\n",
    "    theta here use eta, iota, dec instead of q, cos(iota), sin(dec)\n",
    "    \"\"\"\n",
    "    theta_waveform = theta[:8]\n",
    "    theta_waveform = theta_waveform.at[5].set(0)\n",
    "    ra = theta[9]\n",
    "    dec = theta[10]\n",
    "    hp_test, hc_test = gen_IMRPhenomD_polar(H1_frequency, theta_waveform, f_ref)\n",
    "    align_time = jnp.exp(-1j*2*jnp.pi*H1_frequency*(epoch+theta[5]))\n",
    "    h_test_H1 = H1_response(H1_frequency, hp_test, hc_test, ra, dec, gmst, theta[8]) * align_time\n",
    "    h_test_L1 = L1_response(L1_frequency, hp_test, hc_test, ra, dec, gmst, theta[8]) * align_time\n",
    "    df = H1_frequency[1] - H1_frequency[0]\n",
    "    match_filter_SNR_H1 = 4*jnp.sum((jnp.conj(h_test_H1)*H1_data)/H1_psd*df).real\n",
    "    match_filter_SNR_L1 = 4*jnp.sum((jnp.conj(h_test_L1)*L1_data)/L1_psd*df).real\n",
    "    optimal_SNR_H1 = 4*jnp.sum((jnp.conj(h_test_H1)*h_test_H1)/H1_psd*df).real\n",
    "    optimal_SNR_L1 = 4*jnp.sum((jnp.conj(h_test_L1)*h_test_L1)/L1_psd*df).real\n",
    "\n",
    "    return -((match_filter_SNR_H1-optimal_SNR_H1/2) + (match_filter_SNR_L1-optimal_SNR_L1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_range = jnp.array([[10,80],[0.125,1.0],[-1,1],[-1,1],[0,2000],[-0.1,0.1],[0,2*np.pi],[-1,1],[0,np.pi],[0,2*np.pi],[-1,1]])\n",
    "optimize_prior_range = jnp.array([[10,80],[0.2,0.25],[-1,1],[-1,1],[0,2000],[-0.1,0.1],[0,2*np.pi],[0,np.pi],[0,np.pi],[0,2*np.pi],[-np.pi/2,np.pi/2]]) # eta, iota, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "optimize_result = scipy.optimize.differential_evolution(negative_LogLikelihood, optimize_prior_range, maxiter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_param = jnp.array([ 3.10497857e+01,  2.46759666e-01,  3.04854781e-01, -4.92774588e-01,\n",
    "        5.47223231e+02,  1.29378808e-02,  3.30994042e+00,  3.88802965e-01,\n",
    "        3.41074151e-02,  2.55345319e+00, -9.52109059e-01])\n",
    "\n",
    "test_waveform = gen_IMRPhenomD_polar(H1_frequency, test_param, f_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jimgw.PE.heterodyneLikelihood import make_heterodyne_likelihood_mutliple_detector\n",
    "\n",
    "data_list = [H1_data, L1_data]\n",
    "psd_list = [H1_psd, L1_psd]\n",
    "response_list = [H1_response, L1_response]\n",
    "\n",
    "logL = make_heterodyne_likelihood_mutliple_detector(data_list, psd_list, response_list, gen_IMRPhenomD_polar, ref_param, H1_frequency, gmst, epoch, f_ref, 301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 11\n",
    "n_chains = 1000\n",
    "n_loop_training = 20\n",
    "n_loop_production = 20\n",
    "n_local_steps = 200\n",
    "n_global_steps = 200\n",
    "learning_rate = 0.001\n",
    "max_samples = 100000\n",
    "momentum = 0.9\n",
    "num_epochs = 60\n",
    "batch_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guess_param = ref_param\n",
    "# guess_param = np.array(jnp.repeat(guess_param[None,:],int(n_chains),axis=0)*np.random.normal(loc=1,scale=0.1,size=(int(n_chains),n_dim)))\n",
    "# guess_param[guess_param[:,1]>0.25,1] = 0.249 # eta\n",
    "# guess_param[:,6] = (guess_param[:,6]%(2*jnp.pi))\n",
    "# guess_param[:,7] = (guess_param[:,7]%(jnp.pi))\n",
    "# guess_param[:,8] = (guess_param[:,8]%(jnp.pi))\n",
    "# guess_param[:,9] = (guess_param[:,9]%(2*jnp.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing RNG keys\")\n",
    "rng_key_set = initialize_rng_keys(n_chains, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing MCMC model and normalizing flow model.\")\n",
    "initial_position = jax.random.uniform(rng_key_set[0], shape=(int(n_chains), n_dim)) * 1\n",
    "for i in range(n_dim):\n",
    "    initial_position = initial_position.at[:,i].set(initial_position[:,i]*(prior_range[i,1]-prior_range[i,0])+prior_range[i,0])\n",
    "\n",
    "# from ripple import Mc_eta_to_ms\n",
    "# m1,m2 = jax.vmap(Mc_eta_to_ms)(guess_param[:,:2])\n",
    "# q = m2/m1\n",
    "\n",
    "# initial_position = initial_position.at[:,0].set(guess_param[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import Planck18 as cosmo\n",
    "\n",
    "z = np.linspace(0.002,3,10000)\n",
    "dL = cosmo.luminosity_distance(z).value\n",
    "dVdz = cosmo.differential_comoving_volume(z).value\n",
    "\n",
    "def top_hat(x):\n",
    "    output = 0.\n",
    "    for i in range(n_dim):\n",
    "        output = jax.lax.cond(x[i]>=prior_range[i,0], lambda: output, lambda: -jnp.inf)\n",
    "        output = jax.lax.cond(x[i]<=prior_range[i,1], lambda: output, lambda: -jnp.inf)\n",
    "    return output+jnp.log(jnp.interp(x[4],dL,dVdz))\n",
    "\n",
    "def posterior(theta):\n",
    "    q = theta[1]\n",
    "    iota = jnp.arccos(theta[7])\n",
    "    dec = jnp.arcsin(theta[10])\n",
    "    prior = top_hat(theta)\n",
    "    theta = theta.at[1].set(q/(1+q)**2) # convert q to eta\n",
    "    theta = theta.at[7].set(iota) # convert cos iota to iota\n",
    "    theta = theta.at[10].set(dec) # convert cos dec to dec\n",
    "    return logL(theta) + prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RQSpline(n_dim, 10, [128,128], 8)\n",
    "\n",
    "print(\"Initializing sampler class\")\n",
    "\n",
    "posterior = posterior\n",
    "\n",
    "mass_matrix = jnp.eye(n_dim)\n",
    "mass_matrix = mass_matrix.at[1,1].set(1e-3)\n",
    "mass_matrix = mass_matrix.at[5,5].set(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_sampler = MALA(posterior, True, {\"step_size\": mass_matrix*3e-3})\n",
    "print(\"Running sampler\")\n",
    "\n",
    "nf_sampler = Sampler(\n",
    "    n_dim,\n",
    "    rng_key_set,\n",
    "    local_sampler,\n",
    "    posterior,\n",
    "    model,\n",
    "    n_loop_training=n_loop_training,\n",
    "    n_loop_production = n_loop_production,\n",
    "    n_local_steps=n_local_steps,\n",
    "    n_global_steps=n_global_steps,\n",
    "    n_chains=n_chains,\n",
    "    n_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    momentum=momentum,\n",
    "    batch_size=batch_size,\n",
    "    use_global=True,\n",
    "    keep_quantile=0.,\n",
    "    train_thinning = 40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_sampler.sample(initial_position)\n",
    "chains, log_prob, local_accs, global_accs = nf_sampler.get_sampler_state().values()\n",
    "# np.savez('./GW150914.npz', chains=chains, log_prob=log_prob, local_accs=local_accs, global_accs=global_accs)\n",
    "\n",
    "print(\"Local acceptance rate: \", np.mean(local_accs))\n",
    "print(\"Global acceptance rate: \", np.mean(global_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# n_dim = 11\n",
    "n_dim = 15\n",
    "\n",
    "chains = np.load('/Users/ckng419/Downloads/millilensing/GW150914.npz')['chains']\n",
    "samples_all = chains.reshape(-1,n_dim)\n",
    "# labels = ['$M_c$', '$q$', '$\\chi_1$', '$\\chi_2$', '$d_L$', '$t_c$', '$\\phi_c$', '$\\cos\\iota$', '$\\psi$', '$RA$', '$\\sin({DEC})$', ]\n",
    "labels = ['$M_c$', '$q$', '$\\chi_1$', '$\\chi_2$', '$d_L$', '$t_c$', '$\\phi_c$', '$\\cos\\iota$', '$\\psi$', '$RA$', '$\\sin({DEC})$', '$d_{L2}$', '$t_2$', '$n_1$', '$n_2$']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(n_dim):\n",
    "    df[labels[i]] = samples_all[:,i]\n",
    "\n",
    "for i in [0, 0.5, 1]:\n",
    "    mask1 = (df['$n_1$'] >= i) & (df['$n_1$'] < i + 0.5)\n",
    "    df.loc[mask1, '$n_1$'] = i\n",
    "    mask2 = (df['$n_2$'] >= i) & (df['$n_2$'] < i + 0.5)\n",
    "    df.loc[mask2, '$n_2$'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, corner=True, kind='hist',\n",
    "                 diag_kws=dict(common_norm=False),\n",
    "                 plot_kws=dict(common_norm=False, bins=100, rasterized=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bilby.gw.result import CBCResult\n",
    "# result_GR = CBCResult.from_json(\"./data/GW150914_GR.json.gz\").posterior\n",
    "# result_GR['cos_iota'] = np.cos([float(value) for value in result_GR['iota']])\n",
    "\n",
    "# trigger_time = 1126259462.4\n",
    "\n",
    "# true_param = np.array([result_GR['chirp_mass'].median(), result_GR['mass_ratio'].median(), result_GR['a_1'].median(), result_GR['a_2'].median(), result_GR['luminosity_distance'].median(), result_GR['geocent_time'].median() - trigger_time, result_GR['phase'].median(), result_GR['cos_iota'].median(), result_GR['psi'].median(), result_GR['ra'].median(), np.sin(result_GR['dec']).median()])\n",
    "\n",
    "# for i in range(n_dim):\n",
    "#     g.axes[i,i].axvline(true_param[i], color=sns.color_palette()[3])\n",
    "#     for j in range(i):\n",
    "#         g.axes[i,j].axvline(true_param[j], color=sns.color_palette()[3])\n",
    "#         g.axes[i,j].axhline(true_param[i], color=sns.color_palette()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.figure.savefig('./corner.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
